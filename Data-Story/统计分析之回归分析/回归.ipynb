{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计分析-回归分析与分类分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 概述与大纲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 从建模的目的看回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归分析与分类分析都是一种基于统计模型的统计分析方法。它们都研究因变量（被解释变量）与自变量（解释变量）之间存在的潜在关系，并通过统计模型的形式将这些潜在关系进行显式的表达。不同的是，回归分析中因变量是连续变量，如工资、销售额；而分类分析中因变量是属性变量，如判断邮件“是or否”为垃圾邮件。\n",
    "\n",
    "上一段我们提到，回归是一种基于统计模型的分析方法，因此回归分析的过程本质上一种建模过程。统计建模的主要任务有二：预测与推断。\n",
    "\n",
    "所谓预测，就是利用一个训练完毕的模型$\\hat{f}$，根据输入的自变量$X$获得对应的输出$Y$。在预测任务中，如果模型$\\hat{f}$可以准确地提供预测，那么$\\hat{f}$是什么形式并不重要，而如果$\\hat{f}$的形式非常复杂且难以解释，我们可以将之称为黑盒模型(Black Box)。举一个例子，假设$X_1,X_2,\\cdots ,X_p$是某个病人的血样特征，$Y$测量了病人使用药物后出现严重不良反应的风险，那么如果存在一个模型可以很好地通过$X$以预测$Y$，那自然是再好不过的事了。此时，模型的形式、变量之间的关系在正确预测面前都显得不那么重要。事实上，当前具有强大预测性能的模型大多都是黑盒模型，如强大的Xgboost机器学习算法以及各种深度学习算法，它们的模型可解释性差，我们难以解释其中一些参数的含义与统计性质。\n",
    "\n",
    "与预测相对应的另一任务便是推断。在很多情况下，我们对当$X_1,X_2,\\cdots ,X_p$变化时**如何影响**$Y$更感兴趣，此时，我们估计模型$\\hat{f}$的目的不是为了预测$Y$，而是想明白两者之间的关系，更深层次地讲，我们想要知道模型内各种参数的数值与统计推断性质等等。在这种情况下，模型的可解释性就非常重要了，而通常我们在推断任务中最常使用的模型正是线性回归模型。举一个例子，在研究各因素对商品销售量的场景中，我们会更关注以下问题：哪类媒体对销量有直接的贡献？增加电视广告费用能对销售量带来多少程度的增加？等等，这就是典型的推断问题。\n",
    "\n",
    "弄清楚了预测与推断的区别，我们重新审视一下回归分析：回归分析更加注重对因变量与自变量之间潜在关系的推断，所使用的统计模型也相对简单（一般为线性模型），如果你在比赛中需要分析各变量间的潜在相关关系，便可以考虑使用回归分析。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 课程大纲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本轮课程，我们将先后学习回归分析与分类分析的知识。其中，回归分析中我们主要学习经典线性模型(CLM, Classical Linear Model)与最小二乘估计(OLS)，广义线性模型(GLM)只做简单介绍；分类分析中我们主要学习基于线性模型的Logistics模型与Probit模型。具体大纲如下：\n",
    "\n",
    "· 回归的思想与线性回归模型介绍\n",
    "\n",
    "· OLS估计在经典线性回归模型假设下的统计推断\n",
    "\n",
    "· 线性回归模型中的参数检验\n",
    "\n",
    "· 线性回归模型设定的误差分析\n",
    "\n",
    "· 异方差下回归建模的解决方法\n",
    "\n",
    "首先，我们将了解回归的基本思想，并对最常用的回归模型-经典线性模型的模型形式、模型假设（也称为CLM假设）做基本的介绍。\n",
    "\n",
    "知晓了模型的形式后，下一步自然是进行模型参数的估计，并推断估计参数的统计性质。在线性模型中，这些参数就是每个自变量的系数，我们想知道：使用何种方法进行参数估计呢？参数在这种估计方法下能否接近真实参数呢？估计的误差有多大呢？我们将学习使用最小二乘法(OLS)对线性模型进行估计，并探究OLS估计下各参数的统计性质。可以告诉大家，在满足CLM假设的前提下，OLS估计是经典线性模型最优的参数估计法；基于CLM假设与OLS估计，我们便可以对模型进行各种假设检验，包括参数显著性检验，模型显著性检验等等。\n",
    "\n",
    "然而，理想很丰满，现实很骨感，我们所获得的实验数据不总是能满足CLM假设中的每一条假设。某个假设不成立会给模型参数估计的准确性（无偏性）、稳定性（方差）以及假设检验带来多少影响呢？这就是模型设定误差分析需要研究的内容。最后，若数据不满足CLM假设中的某个假设，需要找到对应的解决办法，在本轮课程，我们重点探讨不满足同方差假设下参数估计方法与参数检验方法的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 回归模型总述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一章节，我们将对“回归”进行宏观的介绍，使大家对回归有直观的理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 回归思想与一般回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 横截面数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "横截面数据是回归分析最主要的分析数据类型，它可以视为在**同一时间点（或抽样时间差异可以被忽略）**上对**多个抽样个体**的观测数据。通常，我们记第$i$个个体的观测数据为$(x_i,y_i)$。如果以抽样时间点与抽样个体数目为维度划分数据类型，除了横截面数据外，还有时间序列数据以及面板数据。时间序列数据为单个个体在不同时间点上的观测数据，而面板数据则是多个个体在不同时间点上的观测数据。对时间序列数据的分析需要用到时间序列分析的知识，对面板数据的分析则是高级计量经济学的内容，在本次课程我们不对它们做介绍。三者的区别如下图所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='横截面数据.png'>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src='横截面数据.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 回归思想——条件均值建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "横截面数据最重要的一个特征，就是我们可以将采集的数据$(x_1,y_1),(x_2,y_2),…,(x_n,y_n)$近似视为来自一个潜在总体的随机样本，即假设\n",
    "$$\n",
    "\\left(x_{1}, y_{1}\\right), \\cdots,\\left(x_{n}, y_{n}\\right) \\sim^{i i d}(x, y)\n",
    "$$\n",
    "我们进行数据分析的最终目的是为了找到$x$与$y$之间的关系并用模型显性表示出来，此时最理想的状态是使用一个**条件分布**刻画$x$对$y$的影响\n",
    "$$\n",
    "F_{y \\mid x}\n",
    "$$\n",
    "即在任意给定$x$的条件下都有一个明确的分布$F$刻画$y$的状态。但是在实际问题中，直接估计这个条件分布几乎是一件不可能的事，且我们也难以对分布进行解释与应用。于是，我们退而求其次通过分布的一般数字特征对两者的关系进行推断，如条件分布的中心位置，形状，即考虑**条件均值、条件方差**\n",
    "$$\n",
    "E(y \\mid x), \\operatorname{Var}(y \\mid x)\n",
    "$$\n",
    "而回归正是利用条件均值$E(y \\mid x)$来刻画$x$与$y$的关系，回归建模的本质也正是“条件均值的建模”。那么，怎么理解条件均值建模呢？我们举一个不典型的例子帮助大家理解。\n",
    "\n",
    "假设某个样本量为100的数据集中，自变量$x$有1,2,3,4,5五个值，样本的因变量$y$都来自以其自变量为均值，方差为1的正态分布。我们想要刻画因变量与自变量之间的变化关系，就要找出可以代表各种类样本内（在此例中以自变量为划分依据）共性的特征，用这些特征来描绘变化关系。最直观也是最简单的特征就是条件均值，即给定$x$的条件下样本的均值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'E(Y|X)')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=list()\n",
    "y=list()\n",
    "for i in [1,2,3,4,5]:\n",
    "    y_norm=stats.norm.rvs(i,1,20,random_state=i).tolist()\n",
    "    y.extend(y_norm)\n",
    "    x1=np.ones(20)*i\n",
    "    x1=x1.tolist()\n",
    "    x.extend(x1)\n",
    "\n",
    "data={'x':x,'y':y}\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "sns.regplot(x='x',y='y',data=df)\n",
    "plt.title('E(Y|X)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上图我们可以看出，$E(y|x=1)=1$,$E(y|x=2)=2$,…,$E(y|x=x_0)=x_0$。通过条件均值，我们可以推断出$x$与$y$的关系可以用模型$y=x+u$来刻画，其中，$u$被称为随机误差，可理解为：除$x$外，其他影响$y$取值的因素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 一般回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上述例子中，我们使用模型$y=x+u$刻画了$x$与$y$的关系，这说明了在这个数据集中我们将模型设定为了\n",
    "$$\n",
    "y=x+u\n",
    "$$\n",
    "事实上，如果我们将上述公式中的$x$泛化成条件均值$E(y|x)$，那么我们就能得到最一般的回归模型\n",
    "$$\n",
    "y=E(y|x)+u\n",
    "$$\n",
    "这也就意味着，所谓回归模型的建模，**本质上就是条件均值建模**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**· 回归模型的条件解读**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般回归模型$y=E(y|x)+u$暗含了一个天然成立的假设：\n",
    "1. 随机误差的条件期望$E(u|x)=0$\n",
    "\n",
    "利用重期望公式，我们可以根据假设1进一步推得下面两个推论:\n",
    "\n",
    "推论1. 随机误差的无条件期望$E(u)=0$——这表示其他因素对$y$的平均影响为0\n",
    "<br>\n",
    "推论2. 随机误差$u$与自变量$x$协方差$Cov(u,x)=0$——这表示其他因素与参与回归的$x$不相关！\n",
    "\n",
    "根据假设1，我们可以将一般回归模型表示成一种新的形式：\n",
    "$$\n",
    "y=E(y|x)+u\\Longleftrightarrow y=m\\left( x \\right) +u, where\\,\\,E\\left( u|x \\right) =0\n",
    "$$\n",
    "在这里，$E(u|x)=0$等价于$m(x)=E(y|x)$。事实上，用这一种形式表示回归模型更常见，也更有利于接下来对模型$m(x)$具体形式的假定，因为这告诉了我们：只要假定随机误差$u$与$x$不相关（这里可理解为其他影响$y$的外生因素与内生因素$x$不相关），我们就可以根据需要假定回归模型的具体形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 线性回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 线性模型形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的学习中我们介绍了回归模型的一般形式。在实际建模中，为了有效的估计，我们必须对模型中$m(x)$的形式进行具体的假定。在所有模型假定形式中，线性回归模型是最常用假定形式，也是回归分析中最重要的模型，是本次课程重点讲解的内容。\n",
    "\n",
    "线性模型假设有：\n",
    "$$\n",
    "m(x)=\\beta_{0}+\\beta_{1} x_{1}+\\cdots+\\beta_{p} x_{p}\n",
    "$$\n",
    "于是，线性回归模型可表示为：\n",
    "$$\n",
    "y=\\beta_{0}+\\beta_{1} x_{1}+\\cdots+\\beta_{p} x_{p}+u, \\quad E\\left(u \\mid x_{1}, \\cdots, x_{p}\\right)=0\n",
    "$$\n",
    "回归分析主要研究如何有效地估计模型中的参数$\\hat{\\beta}_i$，并利用模型进行推断与预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 从简单线性回归到多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**· 用简单线性回归理解对模型的解释**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为大家快速理解线性回归模型，我们先假设$x$是一维的，即只考虑一个因素对$y$的影响，此时亦称模型为简单线性回归，形式为\n",
    "$$\n",
    "y=\\beta_{0}+\\beta_{1} x+u, \\quad E(u \\mid x)=0\n",
    "$$\n",
    "$\\beta_{0}$是截距项，可以理解为$x=0$时$y$的期望值，一般情况下，如果我们回归的任务是推断，则截距通常不重要；\n",
    "<br>\n",
    "$\\beta_{1}=\\frac{\\Delta m(x)}{\\Delta x}$，可理解为$x$每增加一个单位，$y$**平均**增加$\\beta_1$个单位。\n",
    "\n",
    "此后，我们将默认模型含有$E(u|x)=0$的设定（因为只有这样模型才代表回归模型），该条件不再以书面形式写出。\n",
    "\n",
    "我们举一个例子帮助大家理解：\n",
    "\n",
    "**Example1.** 假设大学成绩colGPA与高中成绩hsGPA间关系为\n",
    "$$\n",
    "\\text { colGPA }=\\beta_{0}+\\beta_{1} \\text { hsGPA }+u\n",
    "$$\n",
    "$\\beta_1$系数的解释为：每增加1单位高中成绩，大学成绩会增加$\\beta_1$个单位；由于该模型中自变量只有高中成绩，而大学成绩水平肯定还受其他因素影响，因此该模型中的随机误差包含了如大学测验水平、自主学习能力等因素。\n",
    "\n",
    "注意：设定$E(u|x)=0$的存在暗含了**在该模型中**大学测验水平、自主学习能力等因素与自变量高中成绩无关，但这在**实际问题中**未必成立。而一旦它们存在相关性，就意味着模型假设不符合实际情况，模型估计的有效性与准确性也将受到影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**· 进行全面的回归建模——多元线性回归**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单纯的简单线性模型有很大的局限性，原因有二：\n",
    "\n",
    "1、在实际问题中，因变量$y$通常受多个因素影响，这些因素之间可能彼此之间存在线性相关性（后续的学习中我们将这种现象称为多重共线性），而默认假设$E(u|x)=0$的直接推论(推论2)就是其他影响因素与$x$线性无关，显然不一定符合实际情况。\n",
    "\n",
    "2、如果我们想推断一个变量对另一个变量的因果关系，就要保持尽可能多的其他因素的不变，因此需要尽量把关键因素纳入到回归模型当中，这样便可以控制多个变量，查看某个特定变量变化对自变量的影响。\n",
    "\n",
    "因此在实际问题中，我们更多地使用多元线性回归。一般的多元线性回归模型可写成：\n",
    "$$\n",
    "y=\\beta_{0}+\\beta_{1} x_{1}+\\cdots+\\beta_{k} x_{k}+u\n",
    "$$\n",
    "$u$依旧为随机误差项，它表示除$x_1$,…,$x_k$以外的其他因素对因变量$y$的影响，且同样满足假设\n",
    "$$\n",
    "E\\left(u \\mid x_{1}, \\cdots, x_{k}\\right)=0\n",
    "$$\n",
    "$\\beta_i=\\frac{\\partial m\\left( x \\right)}{\\partial x_i}$是回归函数对变量$x_i$的偏导数，它被解释为**在保持其他自变量不变的情况下，$x_i$每增加一单位，$y$平均增加$\\beta_i$个单位**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_stata('gpa1.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>soph</th>\n",
       "      <th>junior</th>\n",
       "      <th>senior</th>\n",
       "      <th>senior5</th>\n",
       "      <th>male</th>\n",
       "      <th>campus</th>\n",
       "      <th>business</th>\n",
       "      <th>engineer</th>\n",
       "      <th>colGPA</th>\n",
       "      <th>...</th>\n",
       "      <th>greek</th>\n",
       "      <th>car</th>\n",
       "      <th>siblings</th>\n",
       "      <th>bgfriend</th>\n",
       "      <th>clubs</th>\n",
       "      <th>skipped</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>gradMI</th>\n",
       "      <th>fathcoll</th>\n",
       "      <th>mothcoll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  soph  junior  senior  senior5  male  campus  business  engineer  \\\n",
       "0    21.0   0.0     0.0     1.0      0.0   0.0     0.0       1.0       0.0   \n",
       "1    21.0   0.0     0.0     1.0      0.0   0.0     0.0       1.0       0.0   \n",
       "2    20.0   0.0     1.0     0.0      0.0   0.0     0.0       1.0       0.0   \n",
       "3    19.0   1.0     0.0     0.0      0.0   1.0     1.0       1.0       0.0   \n",
       "4    20.0   0.0     1.0     0.0      0.0   0.0     0.0       1.0       0.0   \n",
       "..    ...   ...     ...     ...      ...   ...     ...       ...       ...   \n",
       "136  22.0   0.0     0.0     0.0      1.0   0.0     0.0       1.0       0.0   \n",
       "137  21.0   0.0     0.0     1.0      0.0   1.0     0.0       1.0       0.0   \n",
       "138  20.0   0.0     1.0     0.0      0.0   0.0     0.0       1.0       0.0   \n",
       "139  20.0   0.0     1.0     0.0      0.0   1.0     1.0       1.0       0.0   \n",
       "140  21.0   0.0     0.0     1.0      0.0   1.0     0.0       0.0       0.0   \n",
       "\n",
       "     colGPA  ...  greek  car  siblings  bgfriend  clubs  skipped  alcohol  \\\n",
       "0       3.0  ...    0.0  1.0       1.0       0.0    0.0      2.0      1.0   \n",
       "1       3.4  ...    0.0  1.0       0.0       1.0    1.0      0.0      1.0   \n",
       "2       3.0  ...    0.0  1.0       1.0       0.0    1.0      0.0      1.0   \n",
       "3       3.5  ...    0.0  0.0       1.0       0.0    0.0      0.0      0.0   \n",
       "4       3.6  ...    0.0  1.0       1.0       1.0    0.0      0.0      1.5   \n",
       "..      ...  ...    ...  ...       ...       ...    ...      ...      ...   \n",
       "136     3.0  ...    0.0  1.0       1.0       1.0    1.0      0.0      0.0   \n",
       "137     2.3  ...    0.0  1.0       1.0       0.0    0.0      1.0      1.0   \n",
       "138     2.8  ...    0.0  1.0       1.0       1.0    0.0      0.0      0.3   \n",
       "139     3.4  ...    1.0  1.0       1.0       1.0    1.0      3.0      4.0   \n",
       "140     2.8  ...    0.0  0.0       1.0       1.0    1.0      3.0      2.0   \n",
       "\n",
       "     gradMI  fathcoll  mothcoll  \n",
       "0       1.0       0.0       0.0  \n",
       "1       1.0       1.0       1.0  \n",
       "2       1.0       1.0       1.0  \n",
       "3       0.0       0.0       0.0  \n",
       "4       1.0       1.0       0.0  \n",
       "..      ...       ...       ...  \n",
       "136     1.0       0.0       0.0  \n",
       "137     1.0       0.0       0.0  \n",
       "138     1.0       0.0       0.0  \n",
       "139     1.0       0.0       1.0  \n",
       "140     1.0       1.0       1.0  \n",
       "\n",
       "[141 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d04da679f0afee458c3e357f6d2cf382c79de022618e35f1262af9ecf478f5e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
